{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The SQuaSH InfluxDB data model\n",
    "\n",
    "SQuaSH uses [Chronograf](https://docs.influxdata.com/chronograf/v1.8/) to visualize metrics collected by the [`lsst.verify` framework](https://sqr-019.lsst.io/). In this notebook we show how we designed the SQuaSH data model in InfluxDB and demonstrate the ETL process to get SQuaSH metrics into InfluxDB.\n",
    "\n",
    "In practice, every time a verification job is sent to SQuaSH a background task is responsible for transforming it to the to InfluxDB line protocol and loading it to InfluxDB.\n",
    "\n",
    "This notebook can be used to recreate the SQuaSH database in InfluxDB if needed, for example, if there's a change in the SQuaSH InfluxDB data model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here some important InfluxDB concepts to keep in mind:\n",
    "\n",
    "  * InfluxDB is optimized for time-series data. In InfluxDB the data is indexed and sharded by the timestamp.\n",
    "  * An InfluxDB measurement is equivalent to a table in a relational database;\n",
    "  * An InfluxDB tag is equivalent to an indexed column. Tags are typically metadata used in query predicates.\n",
    "  * An InfluxDB field corresponds to a non-indexed column, fields typically have the main quantity you are interested in, like the metrics in this context.\n",
    "  \n",
    "  \n",
    "In the following cells,  we'll show how to grab the verification jobs from the SQuaSH API, transform and write them to InfluxDB using the the [line protocol](https://docs.influxdata.com/influxdb/v1.8/write_protocols/line_protocol_tutorial/):\n",
    "\n",
    "\n",
    "```#<measurement>[,<tag_key>=<tag_value>[,<tag_key>=<tag_value>]] <field_key>=<field_value>[,<field_key>=<field_value>] [<timestamp>]```\n",
    "\n",
    "## Mapping lsst.verify concepts to InfluxDB\n",
    "\n",
    "The data model created in InfluxDB is based on the following mapping of `lsst.verify` concepts to InfluxDB concepts:\n",
    "\n",
    "  * lsst.verify package -> InfluxDB measurement;\n",
    "  * lsst.verify metadata -> InfluxDB tags or fields (see next section);\n",
    "  * lsst.verify metric name -> InfluxDB field key;\n",
    "  * lsst.verify metric value -> InfluxDB field value;\n",
    "  * CI or LDF pipeline runtime -> InfluxDB timestamp.\n",
    "  \n",
    "**Note**: we avoid using the \"lsst.verify measurement\" terminology and use \"lsst.verify metric value\" instead to avoid collision with \"InfluxDB measurement\" which has another meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping SQuaSH metadata to InfluxDB\n",
    "Using `lsst.verify` the pipeline developer can add metadata to the verification jobs uploaded to SQuaSH. These metadata add information about the context where a given metric is computed, like information about the execution environment, the dataset being processed, etc. Typically job metadata is mapped to InfluxDB tags. However, there are situations where we want to map job metadata to InfluxDB fields. \n",
    "\n",
    "The mapping of job metadata to either InfluxDB tags or fields is defined below.\n",
    "\n",
    "1. By default, if a SQuaSH metadata key is not found in the mapping, the original key name is preserved and it is mapped to an InfluxDB tag.\n",
    "2. If the SQuaSH metadata key is found in the mapping, the `schema` key specifies the mapping. Accepted values are `tag`, `field` or `None`. If `schema` is set to `None`, then the metadata is dropped and won't be written to InfluxDB.\n",
    "3. You can use the mapping to rename metadata keys when appropriate. \n",
    "4. Finally, it is also possible to define an optional transformation on the metadata value (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../src/squash/tasks/utils/mapping.yaml\n",
    "# Defines the mapping from SQuaSH to InfluxDB.\n",
    "#\n",
    "# Each element is a SQuaSH key mapped to an InfluxDB key, schema specfies if\n",
    "# the key is written as an InfluxDB tag or field. It is possible to specify\n",
    "# a transformation for the value too (optional).\n",
    "#\n",
    "# By default, is the SQuaSH key is not present in the mapping\n",
    "# it is added to InfluxDB as a tag using the same name as the SQuaSH key.\n",
    "# If the InlfuxDB key is left blank, it means the that the SQuaSH key should\n",
    "# not be used.\n",
    "\n",
    "ci_id:\n",
    "  key: run_id\n",
    "  schema: field\n",
    "  transformation:\n",
    "\n",
    "run_id:\n",
    "  key: run_id\n",
    "  schema: field\n",
    "  transformation:\n",
    "\n",
    "id:\n",
    "  key: squash_id\n",
    "  schema: field\n",
    "  transformation:\n",
    "\n",
    "url:\n",
    "  key: squash_url\n",
    "  schema: field\n",
    "  transformation: \"Formatter.format_link(data['id'], value)\"\n",
    "\n",
    "# Uniformize the name for execution environment URL\n",
    "run_id_url:\n",
    "  key: run_url\n",
    "  schema: field\n",
    "  transformation: \"Formatter.format_link(data['run_id'], value)\"\n",
    "\n",
    "ci_url:\n",
    "  key: run_url\n",
    "  schema: field\n",
    "  transformation: \"Formatter.format_link(data['ci_id'], value)\"\n",
    "\n",
    "# Uniformize the name for the processed dataset\n",
    "ci_dataset:\n",
    "  key: dataset\n",
    "  schema: tag\n",
    "  transformation:\n",
    "\n",
    "version_tag:\n",
    "  key: version_tag\n",
    "  schema: field\n",
    "  transformation:\n",
    "\n",
    "physical_filter:\n",
    "  key: filter\n",
    "  schema: tag\n",
    "  transformation:\n",
    "\n",
    "filter_name:\n",
    "  key: filter\n",
    "  schema: tag\n",
    "  transformation:\n",
    "\n",
    "date_created:\n",
    "  key: timestamp\n",
    "  schema: field\n",
    "  transformation: \"Formatter.format_timestamp(value)\"\n",
    "\n",
    "date:\n",
    "  key:\n",
    "  schema:\n",
    "  transformation:\n",
    "\n",
    "ci_label:\n",
    "  key:\n",
    "  schema:\n",
    "  transformation:\n",
    "\n",
    "ci_name:\n",
    "  key: pipeline\n",
    "  schema: tag\n",
    "  transformation:\n",
    "\n",
    "code_changes:\n",
    "  key: code_changes\n",
    "  schema: field\n",
    "  transformation: \"self.format_code_changes(data['ci_id'], data['ci_name'])\"\n",
    "\n",
    "code_changes_counts:\n",
    "  key: code_changes_counts\n",
    "  schema: field\n",
    "  transformation: \"self.format_code_changes_counts(data['ci_id'], data['ci_name'])\"\n",
    "\n",
    "packages:\n",
    "  key:\n",
    "  schema:\n",
    "  transformation:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rationale for this mapping is the following:\n",
    "1. The reason for mapping  IDs and corresponding URLs to InfluxDB fields is to [reduce InfluxDB series cardinality](https://docs.influxdata.com/influxdb/v1.7/concepts/schema_and_data_layout/#discouraged-schema-design). We also want to track these information (for example show the IDs in a Chronograf table) so they must be stored as fields.\n",
    "2. We define here a unified data model for mapping metadada from different execution environments. For example, `ci_id` and `run_id` are mapped to `run_id`. `ci_dataset` and `dataset` to `dataset`. These tags don't need to have different names, since the corresponding values can be filtered by the `env_name` tag. \n",
    "3. In the current version of InfluxDB it is not possible to do [math operations with timestamps](https://community.influxdata.com/t/math-operations-on-field-value-and-time/6323/4) so it is useful to add the `timestamp` explicitly as a field. \n",
    "4. `lsst.verify` metadata uses `filter_name`. We decided to rename it to `filter` which is the name of the data ID used in DM pipeline software.\n",
    "5. `ci_label` is not important so we skip that.\n",
    "6. `ci_name` is mapped to `pipeline`. It identifies the pipeline that was executed. Some pipelines can have multiple verification packages.\n",
    "7. We added to the SQuaSH datamodel in InfluxDB the code changes data for pipelines that run in the Jenkins environment.\n",
    "8. We ignore the `packages` metadata for now. \n",
    "9. Note that, by default, keys not listed in this mapping are automatically mapped to InfluxDB tags.\n",
    "\n",
    "\n",
    "See also [InfluxDB schema design and data layout](https://docs.influxdata.com/influxdb/v1.8/concepts/schema_and_data_layout/#general-recommendations) for general recommendations on designing the InfluxDB schema.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sending verification jobs from the SQuaSH API to InfluxDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query the SQuaSH API to read the verifications jobs, transform and write them to InfluxDB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQUASH_API_URL = \"https://squash-sandbox.lsst.codes/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from squash.tasks.utils.transformation import Transformer\n",
    "\n",
    "response = requests.get(SQUASH_API_URL + \"/jobs\").json()\n",
    "ids = response['ids']\n",
    "number_of_jobs = len(ids) \n",
    "print(f\"Found {number_of_jobs} jobs in the SQuaSH API\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These environment variables define the InfluxDB instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INFLUXDB_API_URL = \"https://squash-sandbox.lsst.codes/influxdb\"\n",
    "INFLUXDB_DATABASE = \"squash-sandbox\"\n",
    "INFLUXDB_USERNAME = \"admin\"\n",
    "INFLUXDB_PASSWORD = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the destination InfluxDB database if it does not exist. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from squash.tasks.influxdb import create_influxdb_database\n",
    "\n",
    "status_code = create_influxdb_database(INFLUXDB_DATABASE, INFLUXDB_API_URL, INFLUXDB_USERNAME, INFLUXDB_PASSWORD)\n",
    "status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform jobs to InfluxDB line protocol format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "influxdb_lines = []\n",
    "for id in ids:\n",
    "    \n",
    "    data = requests.get(SQUASH_API_URL + \"/job/{}\".format(id)).json()\n",
    "\n",
    "    dataset = data['ci_dataset']\n",
    "    \n",
    "    print(f'Transforming job {id}, dataset {dataset} to InfluxDB line protocol format.')\n",
    "\n",
    "    transformer = Transformer(squash_api_url=SQUASH_API_URL, data=data)\n",
    "\n",
    "    influxdb_lines.extend(transformer.to_influxdb_line())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write to InfluxDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from squash.tasks.influxdb import write_influxdb_line\n",
    "\n",
    "for line in influxdb_lines:\n",
    "    status_code = write_influxdb_line(line, INFLUXDB_DATABASE, INFLUXDB_API_URL, INFLUXDB_USERNAME, INFLUXDB_PASSWORD)\n",
    "    if status_code != 204:\n",
    "        print(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
